import requests
import pandas as pd
from bs4 import BeautifulSoup
import json
import re

MAP_SECTION = "https://msk.saturn.net/shops/shops?city=all"

EXTRACT_URL = "poo/byids"

CITIES = {
   'Moscow': 'https://msk.saturn.net/shops/shops?city=city_2',
   'Saint Petersburg': 'https://msk.saturn.net/shops/shops?city=city_1',
   'Barnaul': 'https://msk.saturn.net/shops/shops?city=city_3',
   'Volgograd': 'https://msk.saturn.net/shops/shops?city=city_4',
   'Volzhskiy': 'https://msk.saturn.net/shops/shops?city=city_23', 
   'Ekaterinburg': 'https://msk.saturn.net/shops/shops?city=city_5',
   'Kazan': 'https://msk.saturn.net/shops/shops?city=city_6',
   'Krasnodar': 'https://msk.saturn.net/shops/shops?city=city_7',
   'Krasnoyarsk': 'https://msk.saturn.net/shops/shops?city=city_8',
   'Magnitogorsk': 'https://msk.saturn.net/shops/shops?city=city_9',
   'Neftekamsk': 'https://msk.saturn.net/shops/shops?city=city_21',
   'Nizhniy Novgorod': 'https://msk.saturn.net/shops/shops?city=city_10',
   'Novosibirsk': 'https://msk.saturn.net/shops/shops?city=city_12',
   'Orenburg': 'https://msk.saturn.net/shops/shops?city=city_11',
   'Orekhovo-Zuevo': 'https://msk.saturn.net/shops/shops?city=city_22',
   'Podolsk': 'https://msk.saturn.net/shops/shops?city=city_18',
   'Samara': 'https://msk.saturn.net/shops/shops?city=city_14',
   'Sochi': 'https://msk.saturn.net/shops/shops?city=city_15',
   'Sterlitamak': 'https://msk.saturn.net/shops/shops?city=city_20',
   'Tolyatti': 'https://msk.saturn.net/shops/shops?city=city_24',
   'Tomsk': 'https://msk.saturn.net/shops/shops?city=city_25',
   'Ufa': 'https://msk.saturn.net/shops/shops?city=city_16',
   'Chelyabinsk': 'https://msk.saturn.net/shops/shops?city=city_17',
}

def extract_points (URL):

    response = requests.get(f'{URL}{MAP_SECTION}')

    soup = BeautifulSoup(response.text, 'lxml')

    scripts = soup.findAll('script')

    for index, script in enumerate(scripts):

        script_content = script.string

        if script_content is not None and "var pickpoints =" in script_content:

            match = re.search(r"var pickpoints = \[(.+)\]", str(script_content))

            data = json.loads(match.group(0).split('=')[1])
            return data

def update_location (feature_list):
    for feature in feature_list:
        
        modified_feature = {
            'id': feature['id'],
            'lat': feature['coordinates'][0],
            'lng': feature['coordinates'][1],
            'isPost': feature['isWb'], 
            'isWb': feature['isWb'],
            "isExternalPostamat": feature['isExternalPostamat'],
            "workTime": feature['workTime'],
        }

        yield modified_feature


def extract_points (URL):
    response = requests.get(f'{URL}{MAP_SECTION}')
    soup = BeautifulSoup(response.text, 'lxml')

    scripts = soup.findAll('script')
    
    for index, script in enumerate(scripts): 
        script_content = script.string
        
        if script_content is not None and "var pickpoints =" in script_content:
            match = re.search(r"var pickpoints = \[(.+)\]", str(script_content))
            data = json.loads(match.group(0).split('=')[1])
            updated_location_data = update_location(data)

            return updated_location_data

def parse_detailed_info_response (feature_list):
    for feature_id in feature_list:
        
        feature = {}

        try:
            feature = {
                "id": int(feature_id),
                "address": feature_list[feature_id]['address'],
                "wayInfo": feature_list[feature_id]['wayInfo'],
            }
        except:
            feature = {
                "id": int(feature_id),
                "address": feature_list[feature_id]['address'],
                "wayInfo": None,
            }

        yield feature

def extract_detailed_info (URL, df_points):

    url = f'{URL}{EXTRACT_URL}'

    headers = {
        'Content-Type': "application/json; charset=UTF-8",
        'x-requested-with': 'XMLHttpRequest',
    }

    payload = json.dumps(list(df_points['id']))

    response = requests.post(url, headers=headers, data=payload).json()

    df_detailed_info = pd.DataFrame(parse_detailed_info_response(response['value']))

    df_merged = df_points.merge(df_detailed_info.set_index('id'), on='id')

    return df_merged

def to_geojson(data_frame):
    features = []

    for index, row in data_frame.iterrows(): 
        
        feature = {
            "type": "Feature",
            "properties": {
                'isPost': row['isPost'],
                'isWb': row['isWb'],
                'isExternalPostamat': row['isExternalPostamat'],
                'workTime': row['workTime'],
                'address': row['address'],
                'wayInfo': row['wayInfo']
            },
            "geometry": {
                "type": "Point",
                "coordinates": [row['lng'], row['lat']]
            }
        }

        features.append(feature)
    
    featureCollection = {
       "type": "FeatureCollection",
        "features": features
    }

    return featureCollection

def main (city):
    
    if city in CITIES:
        url = CITIES[city]

        df_points = pd.DataFrame( extract_points(url) ) 
        df_detailed_info = extract_detailed_info (url, df_points)
        
        geojson = to_geojson(df_detailed_info)

        print(geojson)
    else:
        return False

if __name__ == '__main__':
    main('am')

import requests
import pandas as pd
from bs4 import BeautifulSoup
import json
import re

MAP_SECTION = "https://www.sogaz.ru/sogaz/about/filials/"

EXTRACT_URL = "poo/byids"

REGIONS = {
    'Moscow and Moscow region': 'https://www.sogaz.ru/sogaz/about/filials/40/',
    'Belgorod region': 'https://www.sogaz.ru/sogaz/about/filials/61/',
    'Bryansk region': 'https://www.sogaz.ru/sogaz/about/filials/63/',
    'Vladimir region': 'https://www.sogaz.ru/sogaz/about/filials/1072/',
    'Voronezh region': 'https://www.sogaz.ru/sogaz/about/filials/73/',
    'Ivanovo region': 'https://www.sogaz.ru/sogaz/about/filials/64/',
    'Kaluga region': 'https://www.sogaz.ru/sogaz/about/filials/65/',
    'Kostroma region': 'https://www.sogaz.ru/sogaz/about/filials/1069/',
    'Kursk region': 'https://www.sogaz.ru/sogaz/about/filials/66/',
    'Lipetsk region': 'https://www.sogaz.ru/sogaz/about/filials/67/',
    'Orel region': 'https://www.sogaz.ru/sogaz/about/filials/68/',
    'Ryazan region': 'https://www.sogaz.ru/sogaz/about/filials/69/',
    'Smolensk region': 'https://www.sogaz.ru/sogaz/about/filials/1071/',
    'Tambov region': 'https://www.sogaz.ru/sogaz/about/filials/1070/',
    'Tver region': 'https://www.sogaz.ru/sogaz/about/filials/71/',
    'Tula region': 'https://www.sogaz.ru/sogaz/about/filials/72/',
    'Yaroslavl region': 'https://www.sogaz.ru/sogaz/about/filials/74/',
    'Amur region': 'https://www.sogaz.ru/sogaz/about/filials/1068/',
    'Magadan region': 'https://www.sogaz.ru/sogaz/about/filials/59/',
    'Kamchatskiy region': 'https://www.sogaz.ru/sogaz/about/filials/1166/',
    'Primorskiy region': 'https://www.sogaz.ru/sogaz/about/filials/55/',
    'Sakha Republic': 'https://www.sogaz.ru/sogaz/about/filials/58/',
    'Sakhalin region': 'https://www.sogaz.ru/sogaz/about/filials/57/',
    'Khabarovsk region': 'https://www.sogaz.ru/sogaz/about/filials/56/',
    'Kirov region': 'https://www.sogaz.ru/sogaz/about/filials/2703/',
    'Nizhniy Novgorod region': 'https://www.sogaz.ru/sogaz/about/filials/86/',
    'Orenburg region': 'https://www.sogaz.ru/sogaz/about/filials/87/',
    'Penza region': 'https://www.sogaz.ru/sogaz/about/filials/2704/',
    'Perm region': 'https://www.sogaz.ru/sogaz/about/filials/88/',
    'Bashkortostan republic': 'https://www.sogaz.ru/sogaz/about/filials/100/',
    'Mariy El republic': 'https://www.sogaz.ru/sogaz/about/filials/2987/',
    'Mordoviya republic': 'https://www.sogaz.ru/sogaz/about/filials/97/',
    'Tatarstan republic': 'https://www.sogaz.ru/sogaz/about/filials/85/',
    'Samara region': 'https://www.sogaz.ru/sogaz/about/filials/92/',
    'Saratov region': 'https://www.sogaz.ru/sogaz/about/filials/98/',
    'Udmurtiya republic': 'https://www.sogaz.ru/sogaz/about/filials/49/',
    'Ulyanovsk region': 'https://www.sogaz.ru/sogaz/about/filials/99/',
    'Chuvashiya republic': 'https://www.sogaz.ru/sogaz/about/filials/101/',
    'Saint Petersburg and Leningrad region': 'https://www.sogaz.ru/sogaz/about/filials/94/',
    'Arkhangelsk region': 'https://www.sogaz.ru/sogaz/about/filials/10/',
    'Vologda region': 'https://www.sogaz.ru/sogaz/about/filials/11/',
    'Kaliningrad region': 'https://www.sogaz.ru/sogaz/about/filials/12/',
    'Murmansk region': 'https://www.sogaz.ru/sogaz/about/filials/90/',
    'Novgorod region': 'https://www.sogaz.ru/sogaz/about/filials/91/',
    'Pskov region': 'https://www.sogaz.ru/sogaz/about/filials/93/',
    'Kareliya republic': 'https://www.sogaz.ru/sogaz/about/filials/89/',
    'Komi republic': 'https://www.sogaz.ru/sogaz/about/filials/95/',
    'Altayskiy region': 'https://www.sogaz.ru/sogaz/about/filials/60/',
    'Zabaykalskiy region': 'https://www.sogaz.ru/sogaz/about/filials/2563/',
    'Irkutsk region': 'https://www.sogaz.ru/sogaz/about/filials/62/',
    'Kemerovo region': 'https://www.sogaz.ru/sogaz/about/filials/78/',
    'Krasnoyarsk region': 'https://www.sogaz.ru/sogaz/about/filials/44/',
    'Novosibirsk region': 'https://www.sogaz.ru/sogaz/about/filials/70/',
    'Omsk region': 'https://www.sogaz.ru/sogaz/about/filials/75/',
    'Buryatiya republic': 'https://www.sogaz.ru/sogaz/about/filials/76/',
    'Khakasiya republic': 'https://www.sogaz.ru/sogaz/about/filials/77/',
    'Tomsk region': 'https://www.sogaz.ru/sogaz/about/filials/1090/',
    'Kurgan region': 'https://www.sogaz.ru/sogaz/about/filials/2562/',
    'Sverdlovsk region': 'https://www.sogaz.ru/sogaz/about/filials/46/',
    'Tumen region': 'https://www.sogaz.ru/sogaz/about/filials/82/',
    'Khanty-Mansiyskiy region': 'https://www.sogaz.ru/sogaz/about/filials/83/',
    'Chelyabinsk region': 'https://www.sogaz.ru/sogaz/about/filials/84/',
    'Yamalo-Nenetskiy region': 'https://www.sogaz.ru/sogaz/about/filials/81/',
    'Astrakhan region': 'https://www.sogaz.ru/sogaz/about/filials/52/',
    'Volgograd region': 'https://www.sogaz.ru/sogaz/about/filials/53/',
    'Krasnodar region': 'https://www.sogaz.ru/sogaz/about/filials/50/',
    'Adygeya republic': 'https://www.sogaz.ru/sogaz/about/filials/3921/',
    'Rostov region': 'https://www.sogaz.ru/sogaz/about/filials/54/',
    'Stavropol region': 'https://www.sogaz.ru/sogaz/about/filials/51/',
}

def extract_points (URL):

    response = requests.get(f'{URL}{MAP_SECTION}')

    soup = BeautifulSoup(response.text, 'lxml')

    scripts = soup.findAll('script')

    for index, script in enumerate(scripts):

        script_content = script.string

        if script_content is not None and "var pickpoints =" in script_content:

            match = re.search(r"var pickpoints = \[(.+)\]", str(script_content))

            data = json.loads(match.group(0).split('=')[1])
            return data

def update_location (feature_list):
    for feature in feature_list:
        
        modified_feature = {
            'id': feature['id'],
            'lat': feature['coordinates'][0],
            'lng': feature['coordinates'][1],
            'isPost': feature['isWb'], 
            'isWb': feature['isWb'],
            "isExternalPostamat": feature['isExternalPostamat'],
            "workTime": feature['workTime'],
        }

        yield modified_feature


def extract_points (URL):
    response = requests.get(f'{URL}{MAP_SECTION}')
    soup = BeautifulSoup(response.text, 'lxml')

    scripts = soup.findAll('script')
    
    for index, script in enumerate(scripts): 
        script_content = script.string
        
        if script_content is not None and "var pickpoints =" in script_content:
            match = re.search(r"var pickpoints = \[(.+)\]", str(script_content))
            data = json.loads(match.group(0).split('=')[1])
            updated_location_data = update_location(data)

            return updated_location_data

def parse_detailed_info_response (feature_list):
    for feature_id in feature_list:
        
        feature = {}

        try:
            feature = {
                "id": int(feature_id),
                "address": feature_list[feature_id]['address'],
                "wayInfo": feature_list[feature_id]['wayInfo'],
            }
        except:
            feature = {
                "id": int(feature_id),
                "address": feature_list[feature_id]['address'],
                "wayInfo": None,
            }

        yield feature

def extract_detailed_info (URL, df_points):

    url = f'{URL}{EXTRACT_URL}'

    headers = {
        'Content-Type': "application/json; charset=UTF-8",
        'x-requested-with': 'XMLHttpRequest',
    }

    payload = json.dumps(list(df_points['id']))

    response = requests.post(url, headers=headers, data=payload).json()

    df_detailed_info = pd.DataFrame(parse_detailed_info_response(response['value']))

    df_merged = df_points.merge(df_detailed_info.set_index('id'), on='id')

    return df_merged

def to_geojson(data_frame):
    features = []

    for index, row in data_frame.iterrows(): 
        
        feature = {
            "type": "Feature",
            "properties": {
                'isPost': row['isPost'],
                'isWb': row['isWb'],
                'isExternalPostamat': row['isExternalPostamat'],
                'workTime': row['workTime'],
                'address': row['address'],
                'wayInfo': row['wayInfo']
            },
            "geometry": {
                "type": "Point",
                "coordinates": [row['lng'], row['lat']]
            }
        }

        features.append(feature)
    
    featureCollection = {
       "type": "FeatureCollection",
        "features": features
    }

    return featureCollection

def main (region):

   if region in REGIONS:
        url = REGIONS[region]

        df_points = pd.DataFrame( extract_points(url) ) 
        df_detailed_info = extract_detailed_info (url, df_points)
        
        geojson = to_geojson(df_detailed_info)

        print(geojson)
    else:
        return False

if __name__ == '__main__':
    main('am')   
